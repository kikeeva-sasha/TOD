{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24485"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "data = pd.read_csv('preprocessed_descriptions.csv')\n",
    "description = data.preprocessed_descriptions.astype(str)\n",
    "\n",
    "words = []\n",
    "for i in description:\n",
    "    # Приводим к нижнему регистру и удаляем знаки пунктуации\n",
    "    i = i.lower()\n",
    "    i = ''.join([char for char in i if char not in string.punctuation])\n",
    "    \n",
    "    words.extend(word_tokenize(i))\n",
    "\n",
    "unique_words = list(set(words))\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    edit_distance_align,\n",
    "    binary_distance,\n",
    "    jaccard_distance,\n",
    "    masi_distance,\n",
    "    interval_distance,\n",
    "    custom_distance,\n",
    "    presence,\n",
    "    fractional_presence,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние между словами tougher и silk: 7\n",
      "Расстояние между словами timey и upto: 5\n",
      "Расстояние между словами cattlemen и syria: 9\n",
      "Расстояние между словами apatite и definately: 8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_words = random.sample(unique_words, 10)\n",
    "for i in range(0, len(random_words)-3, 2):\n",
    "    distance = edit_distance(random_words[i], random_words[i+1])\n",
    "    print(f'Расстояние между словами {random_words[i]} и {random_words[i+1]}: {distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_words(word, k):\n",
    "    dictance_dict = {w:edit_distance(word, w) for w in words}\n",
    "    sorted_dict = dict(sorted(dictance_dict.items(), key=lambda x: x[1]))\n",
    "    for key in list(sorted_dict.keys())[:k]:\n",
    "        print(f'Расстояние от {word} до {key} равно {sorted_dict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние от freedom до fereedom равно 1\n",
      "Расстояние от freedom до fredom равно 1\n",
      "Расстояние от freedom до fredeom равно 2\n"
     ]
    }
   ],
   "source": [
    "words = ['rfeeodmm', 'fereedom', 'fredeom', 'fredom', \n",
    "         'fredoom', 'frrteddmon']\n",
    "\n",
    "nearest_words('freedom', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Инициализация SnowballStemmer и WordNetLemmatizer\n",
    "snb_stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>skyr</th>\n",
       "      <td>skyr</td>\n",
       "      <td>skyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindi</th>\n",
       "      <td>hindi</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thewebgangsta</th>\n",
       "      <td>thewebgangsta</td>\n",
       "      <td>thewebgangsta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indefinite</th>\n",
       "      <td>indefinit</td>\n",
       "      <td>indefinite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakamak</th>\n",
       "      <td>shakamak</td>\n",
       "      <td>shakamak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hunk</th>\n",
       "      <td>hunk</td>\n",
       "      <td>hunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judy</th>\n",
       "      <td>judi</td>\n",
       "      <td>judy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laurien</th>\n",
       "      <td>laurien</td>\n",
       "      <td>laurien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drives</th>\n",
       "      <td>drive</td>\n",
       "      <td>drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groundhog</th>\n",
       "      <td>groundhog</td>\n",
       "      <td>groundhog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                stemmed_word normalized_word\n",
       "word                                        \n",
       "skyr                    skyr            skyr\n",
       "hindi                  hindi           hindi\n",
       "thewebgangsta  thewebgangsta   thewebgangsta\n",
       "indefinite         indefinit      indefinite\n",
       "shakamak            shakamak        shakamak\n",
       "...                      ...             ...\n",
       "hunk                    hunk            hunk\n",
       "judy                    judi            judy\n",
       "laurien              laurien         laurien\n",
       "drives                 drive           drive\n",
       "groundhog          groundhog       groundhog\n",
       "\n",
       "[24485 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_word = [snb_stemmer.stem(word) for word in unique_words]\n",
    "normalized_word = [lemmatizer.lemmatize(word) for word in unique_words]\n",
    "\n",
    "# Создание DataFrame с одинаковой длиной данных и индекса\n",
    "data = {'stemmed_word': stemmed_word, 'normalized_word': normalized_word}\n",
    "words_df = pd.DataFrame(data, index=unique_words)\n",
    "words_df.index.name = 'word'\n",
    "\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
